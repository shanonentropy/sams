{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform PCA regression on the data matrix assembled and saved in the  \"saved_data\" folder\n",
    "\n",
    "In the later part of the code, PCA is performed on moving windows over the entire range of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import allantools\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data matrix\n",
    "#fpath = '../saved_data/week3_fourth_cycle/demeaned_data_matrix_fourth_cycle_week_3'\n",
    "fpath = '../saved_data/week1_cycle1/demeaned_data_matrix_first_cycle_week1'\n",
    "\n",
    "df = pd.read_csv(fpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the df into X and y\n",
    "col_list = df.columns\n",
    "\n",
    "X = df[col_list[1:]]\n",
    "y = df[col_list[0]]; y = y+273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[col_list[0]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lda = (np.floor(y)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_lda_train, y_lda_test = X[:195000], X[195000:], y_lda[:195000], y_lda[195000:]\n",
    "\n",
    "x_label = X.columns.astype('float').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train.index.values, y_lda_train.values, 'k')\n",
    "plt.plot(X_test.index.values, y_lda_test.values, 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform LDA on dataset to isolate the temperature mode\n",
    "# from prev EDA we know the first mode is what we need to isolate\n",
    "\n",
    "n_comps = 3\n",
    "# # Create a Dask PCA object\n",
    "lda = LinearDiscriminantAnalysis(n_components=n_comps, solver='svd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LDA model\n",
    "lda.fit(X_train, y_lda_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate lda mode's top mode\n",
    "\n",
    "lda_mode  = lda.scalings_[:, 0]\n",
    "plt.plot(x_label, lda_mode)\n",
    "\n",
    "# isolate weights for the first mode over the entire range\n",
    "\n",
    "lda_weights = lda.transform(X)[:, 0]\n",
    "\n",
    "plt.plot(lda_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_mode.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights.reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected data set\n",
    "\n",
    "A = np.array(lda_mode).reshape(1, -1)*np.array(lda_weights.reshape(-1, 1))\n",
    "X1 = X - A\n",
    "\n",
    "plt.plot(x_label, X1.iloc[0, :].values)                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X1.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = X1[:195000], X1[195000:], y[:195000], y[195000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of componenets\n",
    "n_comps = 10\n",
    "# # Create a Dask PCA object\n",
    "pca_train = PCA(n_components=n_comps, svd_solver='auto')\n",
    "\n",
    "# Fit the PCA model\n",
    "pca_train.fit_transform(X1_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scree plot\n",
    "# Get explained variance ratio\n",
    "explained_variance_ratio = pca_train.explained_variance_ratio_\n",
    "\n",
    "export_name = '../saved_data/sensor_2_week_1_first_cycle_screeplot.png'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.xticks(range(1, len(explained_variance_ratio) + 1))\n",
    "plt.grid()\n",
    "#plt.savefig(export_name, dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(pca_train.components_.T[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_comps):\n",
    "    plt.plot( pca_train.components_[i])\n",
    "    plt.title('mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_train = (X_train@pca_train.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_comps):\n",
    "    plt.plot(loadings_train[i].values);\n",
    "    plt.title('mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create a moving average PCA with time window growing with each iteration \n",
    "#### at each step save the modes and their loadings to  file\n",
    "\n",
    "\n",
    "#components_gw = []\n",
    "#loadings_gw = []\n",
    "w_size = []\n",
    "training_error, testing_error = [], []\n",
    "lr = LinearRegression()\n",
    "\n",
    "def growing_window_pca_regression(data, y , window_size=10000):\n",
    "    pca_d = PCA(n_components=10)\n",
    "    print('test')\n",
    "    for start in range(0, data.shape[0] - window_size + 1, window_size):\n",
    "        print(start)\n",
    "        window = data.iloc[0:start + window_size, :]\n",
    "        w_size.append(start+window_size)\n",
    "        y_tr =  y.iloc[0:start + window_size]\n",
    "        y_tt =  y.iloc[start + window_size:]\n",
    "        pca_d.fit(window)\n",
    "        loadings = (data@pca_d.components_.T); \n",
    "        lr.fit(window, y_tr)\n",
    "        y_pred_training = lr.predict(window)\n",
    "        y_pred_testing = lr.predict(data.iloc[start + window_size:, :])\n",
    "        training_err = np.round(np.sqrt(mean_squared_error(y_tr, y_pred_training)), 3)\n",
    "        testing_err = np.round(np.sqrt(mean_squared_error(y_tt, y_pred_testing)), 3)\n",
    "        training_error.append(training_err)\n",
    "        testing_error.append(testing_err)\n",
    "        print('training error is {} and the testing error is {}'.format(training_err, testing_err))\n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growing_window_pca_regression(X1, y , window_size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw = pd.DataFrame(list(zip(w_size, training_error, testing_error)))\n",
    "df_gw.columns = ['w_size', 'training_error', 'testing_error']\n",
    "\n",
    "plt.plot(df_gw.w_size.values, df_gw.training_error.values, 'x')\n",
    "plt.plot(df_gw.w_size.values, df_gw.testing_error.values, 'r^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create a moving average PCA with time window growing with each iteration \n",
    "#### at each step save the modes and their loadings to  file\n",
    "\n",
    "\n",
    "components_gw = []\n",
    "loadings_gw = []\n",
    "w_size = []\n",
    "\n",
    "def growing_window_pca(data, window_size=10000):\n",
    "    pca_d = PCA(n_components=10)\n",
    "    print('test')\n",
    "    for start in range(0, data.shape[0] - window_size + 1, window_size):\n",
    "        print(start)\n",
    "        window = data.iloc[0:start + window_size, :]\n",
    "        w_size.append(start+window_size)\n",
    "        #plt.plot(y.iloc[0:start + window_size]); plt.show()\n",
    "        pca_d.fit(window)\n",
    "        components_gw.append(pca_d.components_)\n",
    "        loadings = (data@pca_d.components_.T);  \n",
    "        loadings_gw.append(loadings)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growing_window_pca(X1, window_size=30000)  #10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_size[5]\n",
    "#components_gw[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(components_gw[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 5\n",
    "mode_0 = np.array(components_gw[time_step][0]).reshape(1, -1)*np.array(loadings_gw[time_step][0]).reshape(-1, 1)\n",
    "mode_1 = np.array(components_gw[time_step][1]).reshape(1, -1)*np.array(loadings_gw[time_step][1]).reshape(-1, 1)\n",
    "mode_2 = np.array(components_gw[time_step][2]).reshape(1, -1)*np.array(loadings_gw[time_step][2]).reshape(-1, 1)\n",
    "\n",
    "mode_3 = np.array(components_gw[time_step][3]).reshape(1, -1)*np.array(loadings_gw[time_step][3]).reshape(-1, 1)\n",
    "mode_4 = np.array(components_gw[time_step][4]).reshape(1, -1)*np.array(loadings_gw[time_step][4]).reshape(-1, 1)\n",
    "mode_5 = np.array(components_gw[time_step][5]).reshape(1, -1)*np.array(loadings_gw[time_step][5]).reshape(-1, 1)\n",
    "\n",
    "mode_6 = np.array(components_gw[time_step][6]).reshape(1, -1)*np.array(loadings_gw[time_step][6]).reshape(-1, 1)\n",
    "mode_7 = np.array(components_gw[time_step][7]).reshape(1, -1)*np.array(loadings_gw[time_step][7]).reshape(-1, 1)\n",
    "mode_8 = np.array(components_gw[time_step][8]).reshape(1, -1)*np.array(loadings_gw[time_step][8]).reshape(-1, 1)\n",
    "mode_9 = np.array(components_gw[time_step][9]).reshape(1, -1)*np.array(loadings_gw[time_step][9]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = X1 - mode_0 - mode_1 - mode_2  \n",
    "C = X1 - mode_0 - mode_1 - mode_2  - mode_3 - mode_4 - mode_5 #- mode_6- mode_7 - mode_8 - mode_6\n",
    "D = X1 - mode_0 - mode_1 - mode_2  - mode_3 - mode_4 - mode_5 - mode_6- mode_7 - mode_8# - mode_9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(B.iloc[0, :]); plt.ylim(-1000, 3000);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(C.iloc[0,:]); plt.ylim(-2000, 2000); plt.show()\n",
    "plt.plot(C.iloc[100000,:]); plt.ylim(-2000, 2000); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(D.iloc[0,:]); plt.ylim(-2000, 2000); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of componenets\n",
    "n_comps = 10\n",
    "# # Create a Dask PCA object\n",
    "pca_ = PCA(n_components=n_comps, svd_solver='auto')\n",
    "\n",
    "# Fit the PCA model\n",
    "#X_reduced_train = pca.fit_transform(X_train) \n",
    "pca_.fit_transform(B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_comps):\n",
    "    plt.plot(pca_.components_[i,:].T);\n",
    "    plt.title('mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_ = B@pca_.components_.T\n",
    "for i in range(n_comps):\n",
    "    plt.plot(loadings_[i]);    \n",
    "    plt.title('loading for mode {} after subtracting top 3 modes'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_comps):\n",
    "    pd.plotting.autocorrelation_plot(loadings_[i])\n",
    "    plt.title('ACF plot for mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.plotting.autocorrelation_plot(y)\n",
    "plt.title('ACF plot for temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of componenets\n",
    "n_comps = 10\n",
    "# # Create a Dask PCA object\n",
    "pca_c = PCA(n_components=n_comps, svd_solver='auto')\n",
    "\n",
    "# Fit the PCA model\n",
    "#X_reduced_train = pca.fit_transform(X_train) \n",
    "pca_c.fit_transform(C) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_comps):\n",
    "    plt.plot(pca_.components_[i,:].T);\n",
    "    plt.title('mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_c = C@pca_c.components_.T\n",
    "for i in range(n_comps):\n",
    "    plt.plot(loadings_c[i]);    \n",
    "    plt.title('loading for mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_comps):\n",
    "    pd.plotting.autocorrelation_plot(loadings_c[i])\n",
    "    plt.title('ACF plot for mode {} after subtracting top 7 modes'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of componenets\n",
    "n_comps = 10\n",
    "# # Create a Dask PCA object\n",
    "pca_d = PCA(n_components=n_comps, svd_solver='auto')\n",
    "\n",
    "# Fit the PCA model\n",
    "#X_reduced_train = pca.fit_transform(X_train) \n",
    "pca_d.fit_transform(D) \n",
    "\n",
    "# compute loadings\n",
    "loadings_d = D@pca_d.components_.T\n",
    "for i in range(n_comps):\n",
    "    plt.plot(loadings_d[i]);    \n",
    "    plt.title('loading for mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_comps):\n",
    "    pd.plotting.autocorrelation_plot(loadings_d[i])\n",
    "    plt.title('ACF plot for mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Adev computation mode by mode on loadings from pca on mean centered data\n",
    "\n",
    "\n",
    "for j in range(n_comps):\n",
    "    ### amplitude\n",
    "    yd = loadings_gw[time_step][j]/loadings_gw[time_step][j][0]  \n",
    "    #plt.plot(yd);    \n",
    "    #plt.title('normalized loading for mode {}'.format(j)) #after subtracting top 3 modes\n",
    "    #plt.show()\n",
    "    t= np.logspace(0,10,100)\n",
    "    r=1/14 # sample rate\n",
    "    (t2, ad, ade, adn) = allantools.adev(yd, rate=r, data_type=\"freq\", taus='all')\n",
    "    fig = plt.loglog(t2, ad)\n",
    "    plt.title('ADEV for mode {}'.format(j))\n",
    "    plt.xlabel('log time')\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Adev computation mode by mode on loadings from pca perfromed on data with top 3 modes subtracted\n",
    "\n",
    "for j in range(n_comps):\n",
    "    ### amplitude\n",
    "    yd = loadings_[j]/loadings_[j][0]  \n",
    "    #plt.plot(yd);    \n",
    "    #plt.title('normalized loading for mode {}'.format(j)) #after subtracting top 3 modes\n",
    "    #plt.show()\n",
    "    t= np.logspace(0,10,100)\n",
    "    r=1/14 # sample rate\n",
    "    (t2, ad, ade, adn) = allantools.adev(yd, rate=r, data_type=\"freq\", taus='all')\n",
    "    fig = plt.loglog(t2, ad)\n",
    "    plt.title('ADEV for mode {}'.format(j))\n",
    "    plt.xlabel('log time')\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Adev computation mode by mode on loadings from pca perfromed on data with top 3 modes subtracted\n",
    "\n",
    "for j in range(n_comps):\n",
    "    ### amplitude\n",
    "    yd = loadings_c[j]/loadings_[j][0]  \n",
    "    #plt.plot(yd);    \n",
    "    #plt.title('normalized loading for mode {}'.format(j)) #after subtracting top 3 modes\n",
    "    #plt.show()\n",
    "    t= np.logspace(0,10,100)\n",
    "    r=1/14 # sample rate\n",
    "    (t2, ad, ade, adn) = allantools.adev(yd, rate=r, data_type=\"freq\", taus='all')\n",
    "    fig = plt.loglog(t2, ad)\n",
    "    plt.title('ADEV for mode {}'.format(j))\n",
    "    plt.xlabel('log time')\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Adev computation mode by mode on loadings from pca perfromed on data with top 3 modes subtracted\n",
    "\n",
    "for j in range(n_comps):\n",
    "    ### amplitude\n",
    "    yd = loadings_d[j]/loadings_[j][0]  \n",
    "    #plt.plot(yd);    \n",
    "    #plt.title('normalized loading for mode {}'.format(j)) #after subtracting top 3 modes\n",
    "    #plt.show()\n",
    "    t= np.logspace(0,10,100)\n",
    "    r=1/14 # sample rate\n",
    "    (t2, ad, ade, adn) = allantools.adev(yd, rate=r, data_type=\"freq\", taus='all')\n",
    "    fig = plt.loglog(t2, ad)\n",
    "    plt.title('ADEV for mode {}'.format(j))\n",
    "    plt.xlabel('log time')\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### subtract loadings_ from B  \n",
    "\n",
    "time_step = 5\n",
    "component_0 = pca_.components_[0]\n",
    "mode_B_0 = np.array(component_0[0]).reshape(1, -1)*np.array(loadings_[0]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB = B - mode_B_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(BB.iloc[0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of componenets\n",
    "n_comps = 10\n",
    "# # Create a Dask PCA object\n",
    "pca_bb = PCA(n_components=n_comps, svd_solver='auto')\n",
    "\n",
    "# Fit the PCA model\n",
    "#X_reduced_train = pca.fit_transform(X_train) \n",
    "pca_bb.fit_transform(BB) \n",
    "\n",
    "for i in range(n_comps):\n",
    "    plt.plot(pca_bb.components_[i,:].T);\n",
    "    plt.title('mode {}'.format(i))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# compute loadings\n",
    "loadings_bb = BB@pca_bb.components_.T\n",
    "for i in range(n_comps):\n",
    "    plt.plot(loadings_bb[i]);    \n",
    "    plt.title('loading for mode {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Adev computation mode by mode on loadings from pca perfromed on data with top 3 modes subtracted\n",
    "\n",
    "for j in range(n_comps):\n",
    "    ### amplitude\n",
    "    yd = loadings_bb[j]/loadings_bb[j][0]  \n",
    "    #plt.plot(yd);    \n",
    "    #plt.title('normalized loading for mode {}'.format(j)) #after subtracting top 3 modes\n",
    "    #plt.show()\n",
    "    t= np.logspace(0,10,100)\n",
    "    r=1/14 # sample rate\n",
    "    (t2, ad, ade, adn) = allantools.adev(yd, rate=r, data_type=\"freq\", taus='all')\n",
    "    fig = plt.loglog(t2, ad)\n",
    "    plt.title('ADEV for mode {}'.format(j))\n",
    "    plt.xlabel('log time')\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# =============================================================================\n",
    "# GP w/.o scaling\n",
    "# =============================================================================\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF, ConstantKernel, DotProduct\n",
    "\n",
    "kernel_ = RBF(length_scale = 1, length_scale_bounds = (1e-3, 100))  + WhiteKernel() + ConstantKernel(constant_value = 1, constant_value_bounds = (1e-3, 1e6))\n",
    "gp_model = GaussianProcessRegressor(kernel=kernel_)\n",
    "\n",
    "# fit model\n",
    "gp_model.fit(loadings_train[:, :], y_train)  # Fit the GP on the current batch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_train, std_pred_train = gp_model.predict(loadings_train , return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gp_train = pd.DataFrame({'y_pred_train':y_pred_train, 'std_pred_train':std_pred_train})\n",
    "#df_gp_train.to_csv('../saved_data/gp_training_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(std_pred_train, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_reduced_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_test, std_pred_test = gp_model.predict(X_reduced_test , return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gp_train = pd.DataFrame({'y_pred_test':y_pred_test, 'std_pred_test':std_pred_test,})\n",
    "#df_gp_train.to_csv('../saved_data/gp_testing_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(y_pred_test, y_test,'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot((y_test - y_pred)/std_pred, 'x')\n",
    "plt.plot(y_test/30, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_reduced_all = pca.transform(X)\n",
    "#y_pred_all, std_pred_all = gp_model.predict(X_reduced_all , return_std=True)\n",
    "#df_gp_train = pd.DataFrame({'y_pred_all':y_pred_all, 'std_pred_all':std_pred_all,})\n",
    "#df_gp_train.to_csv('../saved_data/gp_all_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sams",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
