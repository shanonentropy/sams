{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fff90fb-d9ad-4768-a1cf-c59aae33efda",
   "metadata": {},
   "source": [
    "Here we examine MLP for processing PL based temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f42a76a-1194-478f-9861-4fd7dd1d6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c60689f7-6bd6-4efc-ab89-1cae6db203fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data matrix\n",
    "fpath = 'C:\\processed_data_sensor_2\\data_matricies\\svd_data_matrix\\cycle1_week1\\demeaned_data_matrix_first_cycle_week1'\n",
    "df = pd.read_csv(fpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2af9de9d-acf5-4a5a-b0f7-484e9394f112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>613.1581342695605</th>\n",
       "      <th>613.2882643171293</th>\n",
       "      <th>613.4183935430451</th>\n",
       "      <th>613.5485219466715</th>\n",
       "      <th>613.6786495273719</th>\n",
       "      <th>613.8087762845105</th>\n",
       "      <th>613.9389022174508</th>\n",
       "      <th>614.0690273255567</th>\n",
       "      <th>614.1991516081921</th>\n",
       "      <th>...</th>\n",
       "      <th>785.257345426425</th>\n",
       "      <th>785.3858247710828</th>\n",
       "      <th>785.5143024593286</th>\n",
       "      <th>785.6427784905485</th>\n",
       "      <th>785.7712528641274</th>\n",
       "      <th>785.8997255794505</th>\n",
       "      <th>786.0281966359041</th>\n",
       "      <th>786.1566660328739</th>\n",
       "      <th>786.2851337697449</th>\n",
       "      <th>786.413599845903</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-30.0</td>\n",
       "      <td>-98.646169</td>\n",
       "      <td>-53.342284</td>\n",
       "      <td>-118.585942</td>\n",
       "      <td>-211.861645</td>\n",
       "      <td>-145.965698</td>\n",
       "      <td>-187.985642</td>\n",
       "      <td>-186.366585</td>\n",
       "      <td>-314.417365</td>\n",
       "      <td>-294.625502</td>\n",
       "      <td>...</td>\n",
       "      <td>-1469.783244</td>\n",
       "      <td>-1359.474947</td>\n",
       "      <td>-1294.192464</td>\n",
       "      <td>-1471.931681</td>\n",
       "      <td>-1309.164901</td>\n",
       "      <td>-1320.80611</td>\n",
       "      <td>-1364.259771</td>\n",
       "      <td>-1519.678929</td>\n",
       "      <td>-1440.182644</td>\n",
       "      <td>-1145.276082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-30.0</td>\n",
       "      <td>-147.646169</td>\n",
       "      <td>-148.342284</td>\n",
       "      <td>-195.585942</td>\n",
       "      <td>-234.861645</td>\n",
       "      <td>-238.965698</td>\n",
       "      <td>-231.985642</td>\n",
       "      <td>-272.366585</td>\n",
       "      <td>-134.417365</td>\n",
       "      <td>-248.625502</td>\n",
       "      <td>...</td>\n",
       "      <td>-1344.783244</td>\n",
       "      <td>-1442.474947</td>\n",
       "      <td>-1320.192464</td>\n",
       "      <td>-1424.931681</td>\n",
       "      <td>-1411.164901</td>\n",
       "      <td>-1250.80611</td>\n",
       "      <td>-1490.259771</td>\n",
       "      <td>-1271.678929</td>\n",
       "      <td>-1652.182644</td>\n",
       "      <td>-1286.276082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  613.1581342695605  613.2882643171293  613.4183935430451  \\\n",
       "0        -30.0         -98.646169         -53.342284        -118.585942   \n",
       "1        -30.0        -147.646169        -148.342284        -195.585942   \n",
       "\n",
       "   613.5485219466715  613.6786495273719  613.8087762845105  613.9389022174508  \\\n",
       "0        -211.861645        -145.965698        -187.985642        -186.366585   \n",
       "1        -234.861645        -238.965698        -231.985642        -272.366585   \n",
       "\n",
       "   614.0690273255567  614.1991516081921  ...  785.257345426425  \\\n",
       "0        -314.417365        -294.625502  ...      -1469.783244   \n",
       "1        -134.417365        -248.625502  ...      -1344.783244   \n",
       "\n",
       "   785.3858247710828  785.5143024593286  785.6427784905485  785.7712528641274  \\\n",
       "0       -1359.474947       -1294.192464       -1471.931681       -1309.164901   \n",
       "1       -1442.474947       -1320.192464       -1424.931681       -1411.164901   \n",
       "\n",
       "   785.8997255794505  786.0281966359041  786.1566660328739  786.2851337697449  \\\n",
       "0        -1320.80611       -1364.259771       -1519.678929       -1440.182644   \n",
       "1        -1250.80611       -1490.259771       -1271.678929       -1652.182644   \n",
       "\n",
       "   786.413599845903  \n",
       "0      -1145.276082  \n",
       "1      -1286.276082  \n",
       "\n",
       "[2 rows x 1341 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'Unnamed: 0': 'temperature'});\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e54c6002-0ec0-4051-9075-2cdbfe08eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = df.columns\n",
    "col_list[0]\n",
    "\n",
    "# slice the ddf into X and y\n",
    "X = df[col_list[1:]]\n",
    "y = df[col_list[0]]; \n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5b51f6e-b402-451b-b0cf-e6902f38b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement custon dataset class\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)  # Number of samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Return a sample from the dataset\n",
    "        sample = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f701ff1-25c1-45e2-90e8-f6d4cbae6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into tensors\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values.astype('float32'))\n",
    "y_train_tensor = torch.tensor(y_train.values.astype('float32'))\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = MyDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_test_tensor = torch.tensor(X_test.values.astype('float32'))\n",
    "y_test_tensor = torch.tensor(y_test.values.astype('float32'))\n",
    "\n",
    "# Create the dataset\n",
    "test_dataset = MyDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b02ebb6c-8533-464a-9b4e-780424aef83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=60000, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=60000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86802148-7210-4225-a65e-4a5d4f4ebf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define layer sizes\n",
    "\n",
    "input_layer = X.shape[1]\n",
    "h1_layer = 1000\n",
    "h2_layer = 500\n",
    "h3_layer = 250\n",
    "h4_layer = 150\n",
    "h5_layer = 75\n",
    "h6_layer = 30\n",
    "\n",
    "\n",
    "output_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24e91ec1-b570-4bfd-a294-dc45b736fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a neural network \n",
    "\n",
    "class PL_nn_regressor(nn.Module):\n",
    "    def __init__(self, input_layer, h1_layer, h2_layer,h3_layer, h4_layer, h5_layer, h6_layer, output_layer):\n",
    "        super(PL_nn_regressor, self).__init__()\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.fc1 = nn.Linear(input_layer, h1_layer)\n",
    "        self.fc2 = nn.Linear(h1_layer, h2_layer)\n",
    "        self.fc3 = nn.Linear(h2_layer, h3_layer)\n",
    "        self.fc4 = nn.Linear(h3_layer, h4_layer)\n",
    "        self.fc5 = nn.Linear(h4_layer, h5_layer)\n",
    "        self.fc6 = nn.Linear(h5_layer, h6_layer)\n",
    "        self.fc7 = nn.Linear(h6_layer, output_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x\n",
    "    \n",
    "    def feature_extractor(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2b20d49-d69d-4577-b077-b1ced872c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate the model, optimizer and define the loss function\n",
    "model = PL_nn_regressor(input_layer, h1_layer, h2_layer, h3_layer, h4_layer, h5_layer, h6_layer, output_layer)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001, betas = (0.91, 0.99))\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2705bbbe-e926-4f20-8715-765cef8c0f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed6cfa6c-fb82-46c8-a368-c41f881680d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342952,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada4881-a27d-4085-9333-eb6802e38942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Training Loss: 906.2576\n",
      "Epoch 1/30, Validation Loss: 143.0416\n",
      "Epoch 2/30, Training Loss: 130.1379\n",
      "Epoch 2/30, Validation Loss: 312.1274\n",
      "Epoch 3/30, Training Loss: 166.7900\n",
      "Epoch 3/30, Validation Loss: 132.7069\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "num_epochs = 30  # Total number of epochs\n",
    "early_stopping_threshold = 0.1  # Threshold for early stopping based on loss difference\n",
    "epoch_losses = []  # To store loss values for the last 3 epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0.0  # Initialize training loss to 0\n",
    "    \n",
    "    # Train the model (assuming you have a DataLoader for the training set)\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y.unsqueeze(1))  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize model parameters\n",
    "        \n",
    "        train_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)  # Average loss for the epoch\n",
    "\n",
    "    # Store the loss for the current epoch\n",
    "    epoch_losses.append(avg_train_loss)\n",
    "\n",
    "    # If we have at least 3 losses stored, check early stopping condition\n",
    "    if len(epoch_losses) > 3:\n",
    "        # Check if the difference between the max and min loss of the last 3 epochs is <= 0.1\n",
    "        last_three_losses = epoch_losses[-3:]\n",
    "        max_loss = max(last_three_losses)\n",
    "        min_loss = min(last_three_losses)\n",
    "\n",
    "        if max_loss - min_loss <= early_stopping_threshold:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break  # Stop training if early stopping condition is met\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for batch_x, batch_y in test_dataloader:  # Use your validation DataLoader\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1))  # Compute validation loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_dataloader)  # Average validation loss\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#training loop\n",
    "for epoch in range(n_epochs):\n",
    "    #print(epoch)\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        #print(batch_x.shape)\n",
    "        model.train() # set the model to training\n",
    "        optimizer.zero_grad() # clear out the gradients\n",
    "        #### make a forward pass\n",
    "        output =  model(batch_x)\n",
    "        loss = criterion(batch_y.unsqueeze(1), output) #compute loss\n",
    "        #### make a backward pass\n",
    "        loss.backward()  # conpute gradients\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "    \n",
    "    if (epoch + 1) % 2 == 0:  # Print every 100 epochs\n",
    "        print(f'Epoch [{epoch + 1}/{n_epochs}], Loss: {np.sqrt(loss.item()):.4f}')\n",
    "\n",
    "    # Evaluation of training\n",
    "    model_.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model_(X_tensor)\n",
    "        val_loss = criterion(val_outputs, y_tensor).item()\n",
    "        print('',val_loss)\n",
    "    \n",
    "    return val_loss\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1368c91-2b74-451f-a987-debb1680f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing loop\n",
    "#turn off gradients and put model in evaluation mode\n",
    "\n",
    "'''\n",
    "test_loss = []\n",
    "\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_dataloader:\n",
    "        y_pred = model(batch_x)\n",
    "        pred_loss = criterion(batch_y.unsqueeze(1), y_pred)\n",
    "        test_loss.append(np.sqrt(pred_loss.item()))\n",
    "        #print(f'prediction loss = {pred_loss.item():.4f}')\n",
    "        '''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a16d4-2305-4161-8c32-096c6eea82c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf210e-b602-4903-8925-91c96634d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_pred.detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82c18b-4b35-4f7d-b11a-89fcbd3d1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b03c7-bd72-4292-b256-324200634d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train, y_train_pred,'x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98ae5f-8c27-4786-b564-ef0de27ad746",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_pred.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e396249-54a1-46b8-9a03-25162d6849ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(a)) - np.sqrt(np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa8358-913c-4fec-8649-794dcef130e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "y_test_pred = model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d86f9-f1b2-452a-b097-6898c8e79b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, y_test_pred.detach().numpy(), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bdc3b9-7bad-4dff-8934-fdefbcfd860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state dictionary\n",
    "#torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48222c79-98f3-47a4-bf47-6fbec901be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(y_test,test_loss, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212a047-3015-4163-9178-59f2c38cc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and optimizer states\n",
    "'''\n",
    "# Assuming you have the following hyperparameters defined\n",
    "input_layer = 64\n",
    "h1_layer = 128\n",
    "h2_layer = 64\n",
    "h3_layer = 32\n",
    "h4_layer = 16\n",
    "h5_layer = 8\n",
    "h6_layer = 4\n",
    "output_layer = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "'''\n",
    "# Save the model, optimizer, and training state\n",
    "torch.save({\n",
    "    'epoch': epoch,  # The current epoch of training\n",
    "    'model_state_dict': model.state_dict(),  # Model weights\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "    'loss': avg_train_loss,  # Last training loss (optional)\n",
    "    'input_layer': input_layer,  # Model architecture parameters\n",
    "    'h1_layer': h1_layer,\n",
    "    'h2_layer': h2_layer,\n",
    "    'h3_layer': h3_layer,\n",
    "    'h4_layer': h4_layer,\n",
    "    'h5_layer': h5_layer,\n",
    "    'h6_layer': h6_layer,\n",
    "    'output_layer': output_layer,\n",
    "    'learning_rate': learning_rate,  # Training parameters\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "}, 'checkpoint_2_ml_pl_cycle_1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6d17b-b93a-4b5a-b43e-c4d53e1e1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load('checkpoint_2_ml_pl_cycle_1.pth')\n",
    "\n",
    "# Retrieve hyperparameters and training state from the checkpoint\n",
    "input_layer = checkpoint['input_layer']\n",
    "h1_layer = checkpoint['h1_layer']\n",
    "h2_layer = checkpoint['h2_layer']\n",
    "h3_layer = checkpoint['h3_layer']\n",
    "h4_layer = checkpoint['h4_layer']\n",
    "h5_layer = checkpoint['h5_layer']\n",
    "h6_layer = checkpoint['h6_layer']\n",
    "output_layer = checkpoint['output_layer']\n",
    "learning_rate = checkpoint['learning_rate']\n",
    "batch_size = checkpoint['batch_size']\n",
    "epochs = checkpoint['epochs']\n",
    "epoch = checkpoint['epoch']  # Current epoch at the time of saving\n",
    "avg_train_loss = checkpoint['loss']  # Last training loss\n",
    "\n",
    "# Re-initialize the model with the saved architecture hyperparameters\n",
    "model = PL_nn_regressor(input_layer, h1_layer, h2_layer, h3_layer, h4_layer, h5_layer, h6_layer, output_layer)\n",
    "\n",
    "# Load the model's state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Re-initialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Use the saved learning rate\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Optionally, set the model to the appropriate device (e.g., CUDA or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Now, you can resume training using the loaded model, optimizer, and training state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ca1c5-e5b1-4dd9-bebd-4e5cf0fd2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "num_epochs = 30  # Total number of epochs\n",
    "early_stopping_threshold = 0.1  # Threshold for early stopping based on loss difference\n",
    "epoch_losses = []  # To store loss values for the last 3 epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0.0  # Initialize training loss to 0\n",
    "    \n",
    "    # Train the model (assuming you have a DataLoader for the training set)\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y.unsqueeze(1))  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize model parameters\n",
    "        \n",
    "        train_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)  # Average loss for the epoch\n",
    "\n",
    "    # Store the loss for the current epoch\n",
    "    epoch_losses.append(avg_train_loss)\n",
    "\n",
    "    # If we have at least 3 losses stored, check early stopping condition\n",
    "    if len(epoch_losses) > 3:\n",
    "        # Check if the difference between the max and min loss of the last 3 epochs is <= 0.1\n",
    "        last_three_losses = epoch_losses[-3:]\n",
    "        max_loss = max(last_three_losses)\n",
    "        min_loss = min(last_three_losses)\n",
    "\n",
    "        if max_loss - min_loss <= early_stopping_threshold:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break  # Stop training if early stopping condition is met\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for batch_x, batch_y in test_dataloader:  # Use your validation DataLoader\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1))  # Compute validation loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_dataloader)  # Average validation loss\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190d29c-3c1f-43e3-9e23-c762d829a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and optimizer again\n",
    "model = PL_nn_regressor()  # Replace with your model class\n",
    "optimizer = torch.optim.Adam(model.parameters())  # Replace with your optimizer\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load('checkpoint_ml_pl_cycle_1.pth')\n",
    "\n",
    "# Load the model state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Load the optimizer state dict\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Optionally, resume training from the saved epoch and loss\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee22f3-fa34-4333-a27e-d0cb91d42904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model to the correct device (CPU or GPU)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model.load_state_dict(torch.load('model.pth', map_location=device))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
